{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_assignment_using_LSTMs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-5uMT-LLvXx",
        "colab_type": "code",
        "outputId": "75e17b08-5ec0-4e9b-9c5b-fe843dbad3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "! pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.9)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I92fY3CthVS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###https://drive.google.com/open?id=1fy0pk3Xs2uNR6HaM9oVN4830A2I5CqnY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzeTivHAQtP-",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading the text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QybWwfItN-GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id': '1fy0pk3Xs2uNR6HaM9oVN4830A2I5CqnY'})\n",
        "downloaded.GetContentFile('wonderland.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RHLrk_6O-Al",
        "colab_type": "code",
        "outputId": "71158f4e-4907-4216-b6b3-dd40f5b14e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data  wonderland.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq7DmYHHHLKl",
        "colab_type": "text"
      },
      "source": [
        "### The purpose of this tutorial is to create a generative model for text, character-by-character using LSTM recurrent neural networks in Python with Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCfSsYh7OzmD",
        "colab_type": "code",
        "outputId": "3c4a3851-c94e-461c-d5a3-0a0aafd9de40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import sys\n",
        "import string\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Masking\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ljMPc6_O4vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename,encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZR46A86PAik",
        "colab_type": "code",
        "outputId": "463e5dc2-7946-4cef-951a-1de9d32dc313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "num_lines = 0\n",
        "with open(filename, 'r') as f:\n",
        "    for line in f:\n",
        "        num_lines += 1\n",
        "print(\"Number of lines:\")\n",
        "print(num_lines)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines:\n",
            "3328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qevmVUjaf_hr",
        "colab_type": "text"
      },
      "source": [
        "#### We have Alice in the Wonderland text consisting of nearly 3328 lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErtvNEh1gJXU",
        "colab_type": "text"
      },
      "source": [
        "#### Few preprocessing steps to consider:\n",
        "\n",
        "#### We need preprocessing of the given wonderland.txt so that we can define the training data for the network\n",
        "* Removing punctuations except `full-stop` since we will be using it to break up the text into sentences.\n",
        "\n",
        "* Also since there are lot of new-line character `\\n` we can replace them with `full-stop` which will help us break longer sentences into shorter one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJtm_dADdruy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Punctuation(inp_str): \n",
        "  \n",
        "    # punctuation marks \n",
        "    \n",
        "    punctuations = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
        "  \n",
        "    # traverse the given string and if any punctuation \n",
        "    # marks occur replace it with null \n",
        "    for x in inp_str.lower(): \n",
        "        if x in punctuations: \n",
        "            inp_str = inp_str.replace(x, \"\") \n",
        "  \n",
        "    # Print string without punctuation \n",
        "    return inp_str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGq6ZyCRlyTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_text = Punctuation(raw_text)\n",
        "new_text = new_text.replace('\\n','.')\n",
        "new_text = new_text.replace('\\ufeff','')\n",
        "new_text = new_text.split('.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CITUx120wOVw",
        "colab_type": "code",
        "outputId": "5fb15cf8-d13f-48f6-f6b6-6d5c4b9ad02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(new_text)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7gLaQWqwPw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen=0\n",
        "for line in new_text:\n",
        "  if len(line)>maxlen:\n",
        "    maxlen=len(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN6daH06xeSh",
        "colab_type": "code",
        "outputId": "07124f9e-3cdd-4355-a214-f7660be4056f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "maxlen"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dXsWo3ZICTu",
        "colab_type": "text"
      },
      "source": [
        "#### Create a new list `final_text`. It is a list of strings of size nearly 72.\n",
        "\n",
        "Note all the punctuations are removed and we have simple strings of characters `a-z` (lower case only) and `space` character. \n",
        "\n",
        "Since we are processing characters we need our network to learn `space` character also so that it can form words of its own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FbHZh6JDNkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_text = []\n",
        "for line in new_text:\n",
        "  if line == '':\n",
        "    continue\n",
        "  final_text.append(line)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKh5eQFvD_wX",
        "colab_type": "code",
        "outputId": "5d2a914c-cac8-434b-81b5-1fd5a05c157a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(final_text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISm2oCvnIdtS",
        "colab_type": "text"
      },
      "source": [
        "#### Check out distinct characters in our `final_text`  and create a vocabulory using them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Fb46G7K8Dm",
        "colab_type": "code",
        "outputId": "33f69339-34ae-438e-cda6-a359dcabd789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "final_str = ' '.join(final_text)\n",
        "chars = sorted(list(set(final_str)))\n",
        "print(chars)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h06RqbKLOJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(chars,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dDO7jgrLSzo",
        "colab_type": "code",
        "outputId": "f26f7ea2-b2b7-4ead-8cd3-39f7810f047d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uywjE0mJ6dx",
        "colab_type": "text"
      },
      "source": [
        "#### Define a padding character `PAD` with index `0`. Importance of padding explained little later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNDDTTMdMkK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_int['PAD'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbXgYXtkMtab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = {v: k for k, v in char_to_int.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hromGWQKPFma",
        "colab_type": "code",
        "outputId": "11aa84cb-6f15-49c0-da3f-07ed9476955d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "int_to_char"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'PAD',\n",
              " 1: ' ',\n",
              " 2: 'a',\n",
              " 3: 'b',\n",
              " 4: 'c',\n",
              " 5: 'd',\n",
              " 6: 'e',\n",
              " 7: 'f',\n",
              " 8: 'g',\n",
              " 9: 'h',\n",
              " 10: 'i',\n",
              " 11: 'j',\n",
              " 12: 'k',\n",
              " 13: 'l',\n",
              " 14: 'm',\n",
              " 15: 'n',\n",
              " 16: 'o',\n",
              " 17: 'p',\n",
              " 18: 'q',\n",
              " 19: 'r',\n",
              " 20: 's',\n",
              " 21: 't',\n",
              " 22: 'u',\n",
              " 23: 'v',\n",
              " 24: 'w',\n",
              " 25: 'x',\n",
              " 26: 'y',\n",
              " 27: 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGC6FTjIoo-",
        "colab_type": "text"
      },
      "source": [
        "#### Note that we have only 2845 individual strings in our `final_text` data. To train network we will need quite large amout of sequences. Let's create the sequences by passing a sliding window on each of the strings in our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAed1C0k7xaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_seq = []\n",
        "output_seq = []\n",
        "for mystring in final_text:\n",
        "  for i in range(1,len(mystring)):\n",
        "    seq_in = mystring[:i]\n",
        "    seq_out = mystring[i]\n",
        "    input_seq.append(seq_in)\n",
        "    output_seq.append(seq_out)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AlClCn_Umol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4f99f01d-4eb9-4304-b4f5-2080e3b0581d"
      },
      "source": [
        "for i in range(3):\n",
        "  print(final_text[i])\n",
        "  "
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chapter i\n",
            " down the rabbithole\n",
            "alice was beginning to get very tired of sitting by her sister on the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wguc1qXI87q",
        "colab_type": "text"
      },
      "source": [
        "#### This is our dataset preparation for RNN model. We feed in a sequence of characters and get an output character which has maximum probability based on the input fed characters. See sequence `samples` below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4JGZLDKUSIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "283177a3-88ea-4979-803a-3f92f360b71a"
      },
      "source": [
        "for i in range(20):\n",
        "  print(\"Input:\", input_seq[i], \"Output:\", output_seq[i])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: c Output: h\n",
            "Input: ch Output: a\n",
            "Input: cha Output: p\n",
            "Input: chap Output: t\n",
            "Input: chapt Output: e\n",
            "Input: chapte Output: r\n",
            "Input: chapter Output:  \n",
            "Input: chapter  Output: i\n",
            "Input:   Output: d\n",
            "Input:  d Output: o\n",
            "Input:  do Output: w\n",
            "Input:  dow Output: n\n",
            "Input:  down Output:  \n",
            "Input:  down  Output: t\n",
            "Input:  down t Output: h\n",
            "Input:  down th Output: e\n",
            "Input:  down the Output:  \n",
            "Input:  down the  Output: r\n",
            "Input:  down the r Output: a\n",
            "Input:  down the ra Output: b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwTf4m7uJNfo",
        "colab_type": "text"
      },
      "source": [
        "#### So final data for our LSTM model has now 129829 input-output pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwg-6ry0Qk3a",
        "colab_type": "code",
        "outputId": "c2c9fb5b-4499-4133-ecdd-065abde30daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(input_seq)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNH2j4CgQkmy",
        "colab_type": "code",
        "outputId": "0cca36d4-ca2c-4244-ae6f-ffa5656d6648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(output_seq)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh_MYv5SQrLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX=[]\n",
        "dataY=[]\n",
        "for i in range(len(input_seq)):\n",
        "  seq_in = input_seq[i]\n",
        "  seq_out = output_seq[i]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCdqD6PH_kl-",
        "colab_type": "code",
        "outputId": "b988f64d-b7b5-465c-8f77-63c07f757ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(dataX)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQI7wyHgXgOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen=0\n",
        "for li in dataX:\n",
        "  if maxlen<len(li):\n",
        "    maxlen=len(li)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpaX74roXw97",
        "colab_type": "code",
        "outputId": "d77c4789-d790-4328-eb8d-6b8ceb7dedcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "maxlen"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GhIT2KNJaw6",
        "colab_type": "text"
      },
      "source": [
        "### PADDING SEQUENCES\n",
        "\n",
        "To feed our LSTM network in batch we will try to make all sequences of same-length by padding each sequence with some `padding character` defined by us. Note that this padding character will be different from the existing characters in our dataset. Its complete purpose is just to create a batch of same length sequences for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z58ZkENpXyK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX_padded = pad_sequences(dataX, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIDJcv8QYCky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen=72\n",
        "for li in dataX_padded:\n",
        "  if maxlen<len(li):\n",
        "    maxlen=len(li)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdqJKyTRYFFh",
        "colab_type": "code",
        "outputId": "fa3d8bba-9b33-4d73-f11f-78fec51354f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "maxlen"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YjjWYc9NMC0",
        "colab_type": "text"
      },
      "source": [
        "So now we have padded input data where each sequence is of same length 72. check out `dataX_padded`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgrE0ZZnYFyC",
        "colab_type": "code",
        "outputId": "f62f10c9-fb60-4a23-8457-ce347d2a7ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "dataX_padded"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  0,  0, ...,  0,  0,  0],\n",
              "       [ 4,  9,  0, ...,  0,  0,  0],\n",
              "       [ 4,  9,  2, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [19,  6, 14, ...,  0,  0,  0],\n",
              "       [19,  6, 14, ...,  0,  0,  0],\n",
              "       [19,  6, 14, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tksOOKRgQin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab529430-4446-4988-d192-b9228df7c549"
      },
      "source": [
        "n_patterns = len(dataX_padded)\n",
        "print(\"Total input-output patterns in our dataset: \", n_patterns)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total input-output patterns in our dataset:  129829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ri9CvwgXke",
        "colab_type": "code",
        "outputId": "898c070e-812d-43cf-d698-8ab1a763bfcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "seq_length = maxlen\n",
        "print(\"Length of padded sequences: \",seq_length)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of padded sequences:  72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYA-16x0Ojq",
        "colab_type": "code",
        "outputId": "8dd295a9-5c43-4524-f16c-373d3caead27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "n_vocab = len(chars)\n",
        "print(\"Total characters in our vocab {'a-z' and ' '}: \" , n_vocab)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters in our vocab {'a-z' and ' '}:  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY38potXNfef",
        "colab_type": "text"
      },
      "source": [
        "Now that we have prepared our training data we need to transform it so that it is suitable for use with Keras.\n",
        "\n",
        "First we must transform the list of input sequences into the form [samples, time steps, features] expected by an LSTM network.\n",
        "\n",
        "Next we need to rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses the sigmoid activation function by default.\n",
        "\n",
        "Finally, we need to convert the output patterns (single characters converted to integers) into a one hot encoding. This is so that we can configure the network to predict the probability of each of the 28 different characters in the vocabulary (an easier representation) rather than trying to force it to predict precisely the next character. Each y value is converted into a sparse vector with a length of 28, full of zeros except with a 1 in the column for the letter (integer) that the pattern represents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrEAajtKYIzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX_padded, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrh8sL1IgMMV",
        "colab_type": "code",
        "outputId": "16e1dd9d-13a5-44cb-da28-904d4e355994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129829, 72, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14lZHUUmg6Wk",
        "colab_type": "code",
        "outputId": "984cdac4-edf2-4b13-c003-a1fb06bdc822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "features = X.shape[2]\n",
        "print(\"Feature for each character is the character index in our vocab. No. of features: \", features)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature for each character is the character index in our vocab. No. of features:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQ49O9vN3yJ",
        "colab_type": "text"
      },
      "source": [
        "In our vocabulory, character `p` has index 17. Check out its one-hot encoded vector. It will have `1` only at the `17th` position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfMR7IdcW6ur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f85fcee2-dba8-4f55-a73f-35e87e0f2fe0"
      },
      "source": [
        "dataY[2]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfBT3PEsW83h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e5a00fed-085f-48a9-9f90-0cece55f044d"
      },
      "source": [
        "y[2]"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFeiqJg-hFQq",
        "colab_type": "code",
        "outputId": "da0906d1-11c2-4fa2-c33c-da988d82aa80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129829, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNoBmugJcxJF",
        "colab_type": "text"
      },
      "source": [
        "### Creating our model\n",
        "\n",
        "* Remember that only purpose of adding ``'PAD'`` with index `0` was to make all the input sequences of same size. Then we use a Masking layer that skips those special timestamps like they don't exist.\n",
        "Note that if we pad without masking, padded value will be regarded as actual value, thus, it becomes noise in data. Refer [how-to-feed-lstm-with-different-input-array-sizes using padding](https://datascience.stackexchange.com/questions/48796/how-to-feed-lstm-with-different-input-array-sizes) for the same.\n",
        "\n",
        "* Our model is simple comprising of two layers of LSTM and one Dense layer to apply softmax.\n",
        "Before sending the input to LSTM (first layer) we will use dropout of 0.1. And again before sending the first LSTM layer output to second LSTM layer we will apply dropout. Note that no dropout is applied before Dense layer (we prefer that the softmax layer sees all the final activation values before making decision)\n",
        "\n",
        "* Check out the model details using `model.summary()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llTnSfaBgew9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Masking(mask_value=0, input_shape=(seq_length, features)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEL3QGMch9N4",
        "colab_type": "code",
        "outputId": "605ba06c-2a97-414a-cb6d-cd0c30c60593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking_5 (Masking)          (None, 72, 1)             0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 72, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 72, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 72, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 28)                7196      \n",
            "=================================================================\n",
            "Total params: 796,700\n",
            "Trainable params: 796,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dusCWALMKi3-",
        "colab_type": "text"
      },
      "source": [
        "### Model training for 100 epochs and batch-size 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1WS_n4iUA8",
        "colab_type": "code",
        "outputId": "33071614-f8da-46e2-c016-4e774613e115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-2-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 04:07:32.625015 140424021329792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 04:07:32.657660 140424021329792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "129829/129829 [==============================] - 289s 2ms/step - loss: 2.7441\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.74415, saving model to weights-improvement-2-01-2.7441.hdf5\n",
            "Epoch 2/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 2.4857\n",
            "\n",
            "Epoch 00002: loss improved from 2.74415 to 2.48569, saving model to weights-improvement-2-02-2.4857.hdf5\n",
            "Epoch 3/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 2.2977\n",
            "\n",
            "Epoch 00003: loss improved from 2.48569 to 2.29766, saving model to weights-improvement-2-03-2.2977.hdf5\n",
            "Epoch 4/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 2.1607\n",
            "\n",
            "Epoch 00004: loss improved from 2.29766 to 2.16071, saving model to weights-improvement-2-04-2.1607.hdf5\n",
            "Epoch 5/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 2.0581\n",
            "\n",
            "Epoch 00005: loss improved from 2.16071 to 2.05807, saving model to weights-improvement-2-05-2.0581.hdf5\n",
            "Epoch 6/100\n",
            "129829/129829 [==============================] - 285s 2ms/step - loss: 1.9746\n",
            "\n",
            "Epoch 00006: loss improved from 2.05807 to 1.97463, saving model to weights-improvement-2-06-1.9746.hdf5\n",
            "Epoch 7/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.9173\n",
            "\n",
            "Epoch 00007: loss improved from 1.97463 to 1.91729, saving model to weights-improvement-2-07-1.9173.hdf5\n",
            "Epoch 8/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.8667\n",
            "\n",
            "Epoch 00008: loss improved from 1.91729 to 1.86673, saving model to weights-improvement-2-08-1.8667.hdf5\n",
            "Epoch 9/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.8223\n",
            "\n",
            "Epoch 00009: loss improved from 1.86673 to 1.82232, saving model to weights-improvement-2-09-1.8223.hdf5\n",
            "Epoch 10/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.7864\n",
            "\n",
            "Epoch 00010: loss improved from 1.82232 to 1.78642, saving model to weights-improvement-2-10-1.7864.hdf5\n",
            "Epoch 11/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.7539\n",
            "\n",
            "Epoch 00011: loss improved from 1.78642 to 1.75391, saving model to weights-improvement-2-11-1.7539.hdf5\n",
            "Epoch 12/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.7235\n",
            "\n",
            "Epoch 00012: loss improved from 1.75391 to 1.72351, saving model to weights-improvement-2-12-1.7235.hdf5\n",
            "Epoch 13/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.7003\n",
            "\n",
            "Epoch 00013: loss improved from 1.72351 to 1.70034, saving model to weights-improvement-2-13-1.7003.hdf5\n",
            "Epoch 14/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.6713\n",
            "\n",
            "Epoch 00014: loss improved from 1.70034 to 1.67135, saving model to weights-improvement-2-14-1.6713.hdf5\n",
            "Epoch 15/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.6491\n",
            "\n",
            "Epoch 00015: loss improved from 1.67135 to 1.64910, saving model to weights-improvement-2-15-1.6491.hdf5\n",
            "Epoch 16/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.6299\n",
            "\n",
            "Epoch 00016: loss improved from 1.64910 to 1.62994, saving model to weights-improvement-2-16-1.6299.hdf5\n",
            "Epoch 17/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.6114\n",
            "\n",
            "Epoch 00017: loss improved from 1.62994 to 1.61136, saving model to weights-improvement-2-17-1.6114.hdf5\n",
            "Epoch 18/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.5898\n",
            "\n",
            "Epoch 00018: loss improved from 1.61136 to 1.58979, saving model to weights-improvement-2-18-1.5898.hdf5\n",
            "Epoch 19/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.5778\n",
            "\n",
            "Epoch 00019: loss improved from 1.58979 to 1.57785, saving model to weights-improvement-2-19-1.5778.hdf5\n",
            "Epoch 20/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.5616\n",
            "\n",
            "Epoch 00020: loss improved from 1.57785 to 1.56163, saving model to weights-improvement-2-20-1.5616.hdf5\n",
            "Epoch 21/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.5458\n",
            "\n",
            "Epoch 00021: loss improved from 1.56163 to 1.54577, saving model to weights-improvement-2-21-1.5458.hdf5\n",
            "Epoch 22/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.5336\n",
            "\n",
            "Epoch 00022: loss improved from 1.54577 to 1.53365, saving model to weights-improvement-2-22-1.5336.hdf5\n",
            "Epoch 23/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.5226\n",
            "\n",
            "Epoch 00023: loss improved from 1.53365 to 1.52265, saving model to weights-improvement-2-23-1.5226.hdf5\n",
            "Epoch 24/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.5097\n",
            "\n",
            "Epoch 00024: loss improved from 1.52265 to 1.50971, saving model to weights-improvement-2-24-1.5097.hdf5\n",
            "Epoch 25/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.4967\n",
            "\n",
            "Epoch 00025: loss improved from 1.50971 to 1.49673, saving model to weights-improvement-2-25-1.4967.hdf5\n",
            "Epoch 26/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.4884\n",
            "\n",
            "Epoch 00026: loss improved from 1.49673 to 1.48836, saving model to weights-improvement-2-26-1.4884.hdf5\n",
            "Epoch 27/100\n",
            "129829/129829 [==============================] - 285s 2ms/step - loss: 1.4761\n",
            "\n",
            "Epoch 00027: loss improved from 1.48836 to 1.47613, saving model to weights-improvement-2-27-1.4761.hdf5\n",
            "Epoch 28/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.4678\n",
            "\n",
            "Epoch 00028: loss improved from 1.47613 to 1.46784, saving model to weights-improvement-2-28-1.4678.hdf5\n",
            "Epoch 29/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.4548\n",
            "\n",
            "Epoch 00029: loss improved from 1.46784 to 1.45478, saving model to weights-improvement-2-29-1.4548.hdf5\n",
            "Epoch 30/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.4466\n",
            "\n",
            "Epoch 00030: loss improved from 1.45478 to 1.44664, saving model to weights-improvement-2-30-1.4466.hdf5\n",
            "Epoch 31/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.4361\n",
            "\n",
            "Epoch 00031: loss improved from 1.44664 to 1.43614, saving model to weights-improvement-2-31-1.4361.hdf5\n",
            "Epoch 32/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.4287\n",
            "\n",
            "Epoch 00032: loss improved from 1.43614 to 1.42873, saving model to weights-improvement-2-32-1.4287.hdf5\n",
            "Epoch 33/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.4180\n",
            "\n",
            "Epoch 00033: loss improved from 1.42873 to 1.41803, saving model to weights-improvement-2-33-1.4180.hdf5\n",
            "Epoch 34/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.4111\n",
            "\n",
            "Epoch 00034: loss improved from 1.41803 to 1.41114, saving model to weights-improvement-2-34-1.4111.hdf5\n",
            "Epoch 35/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.4069\n",
            "\n",
            "Epoch 00035: loss improved from 1.41114 to 1.40693, saving model to weights-improvement-2-35-1.4069.hdf5\n",
            "Epoch 36/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.3977\n",
            "\n",
            "Epoch 00036: loss improved from 1.40693 to 1.39765, saving model to weights-improvement-2-36-1.3977.hdf5\n",
            "Epoch 37/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.3903\n",
            "\n",
            "Epoch 00037: loss improved from 1.39765 to 1.39031, saving model to weights-improvement-2-37-1.3903.hdf5\n",
            "Epoch 38/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.3829\n",
            "\n",
            "Epoch 00038: loss improved from 1.39031 to 1.38289, saving model to weights-improvement-2-38-1.3829.hdf5\n",
            "Epoch 39/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.3760\n",
            "\n",
            "Epoch 00039: loss improved from 1.38289 to 1.37596, saving model to weights-improvement-2-39-1.3760.hdf5\n",
            "Epoch 40/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.3694\n",
            "\n",
            "Epoch 00040: loss improved from 1.37596 to 1.36943, saving model to weights-improvement-2-40-1.3694.hdf5\n",
            "Epoch 41/100\n",
            "129829/129829 [==============================] - 286s 2ms/step - loss: 1.3653\n",
            "\n",
            "Epoch 00041: loss improved from 1.36943 to 1.36527, saving model to weights-improvement-2-41-1.3653.hdf5\n",
            "Epoch 42/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.3558\n",
            "\n",
            "Epoch 00042: loss improved from 1.36527 to 1.35583, saving model to weights-improvement-2-42-1.3558.hdf5\n",
            "Epoch 43/100\n",
            "129829/129829 [==============================] - 274s 2ms/step - loss: 1.3564\n",
            "\n",
            "Epoch 00043: loss did not improve from 1.35583\n",
            "Epoch 44/100\n",
            "129829/129829 [==============================] - 271s 2ms/step - loss: 1.3463\n",
            "\n",
            "Epoch 00044: loss improved from 1.35583 to 1.34634, saving model to weights-improvement-2-44-1.3463.hdf5\n",
            "Epoch 45/100\n",
            "129829/129829 [==============================] - 271s 2ms/step - loss: 1.3396\n",
            "\n",
            "Epoch 00045: loss improved from 1.34634 to 1.33957, saving model to weights-improvement-2-45-1.3396.hdf5\n",
            "Epoch 46/100\n",
            "129829/129829 [==============================] - 270s 2ms/step - loss: 1.3383\n",
            "\n",
            "Epoch 00046: loss improved from 1.33957 to 1.33831, saving model to weights-improvement-2-46-1.3383.hdf5\n",
            "Epoch 47/100\n",
            "129829/129829 [==============================] - 270s 2ms/step - loss: 1.3304\n",
            "\n",
            "Epoch 00047: loss improved from 1.33831 to 1.33041, saving model to weights-improvement-2-47-1.3304.hdf5\n",
            "Epoch 48/100\n",
            "129829/129829 [==============================] - 269s 2ms/step - loss: 1.3303\n",
            "\n",
            "Epoch 00048: loss improved from 1.33041 to 1.33032, saving model to weights-improvement-2-48-1.3303.hdf5\n",
            "Epoch 49/100\n",
            "129829/129829 [==============================] - 268s 2ms/step - loss: 1.3222\n",
            "\n",
            "Epoch 00049: loss improved from 1.33032 to 1.32220, saving model to weights-improvement-2-49-1.3222.hdf5\n",
            "Epoch 50/100\n",
            "129829/129829 [==============================] - 268s 2ms/step - loss: 1.3165\n",
            "\n",
            "Epoch 00050: loss improved from 1.32220 to 1.31652, saving model to weights-improvement-2-50-1.3165.hdf5\n",
            "Epoch 51/100\n",
            "129829/129829 [==============================] - 267s 2ms/step - loss: 1.3137\n",
            "\n",
            "Epoch 00051: loss improved from 1.31652 to 1.31375, saving model to weights-improvement-2-51-1.3137.hdf5\n",
            "Epoch 52/100\n",
            "129829/129829 [==============================] - 276s 2ms/step - loss: 1.3100\n",
            "\n",
            "Epoch 00052: loss improved from 1.31375 to 1.31001, saving model to weights-improvement-2-52-1.3100.hdf5\n",
            "Epoch 53/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.3065\n",
            "\n",
            "Epoch 00053: loss improved from 1.31001 to 1.30649, saving model to weights-improvement-2-53-1.3065.hdf5\n",
            "Epoch 54/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2988\n",
            "\n",
            "Epoch 00054: loss improved from 1.30649 to 1.29879, saving model to weights-improvement-2-54-1.2988.hdf5\n",
            "Epoch 55/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.2955\n",
            "\n",
            "Epoch 00055: loss improved from 1.29879 to 1.29547, saving model to weights-improvement-2-55-1.2955.hdf5\n",
            "Epoch 56/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2898\n",
            "\n",
            "Epoch 00056: loss improved from 1.29547 to 1.28976, saving model to weights-improvement-2-56-1.2898.hdf5\n",
            "Epoch 57/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2900\n",
            "\n",
            "Epoch 00057: loss did not improve from 1.28976\n",
            "Epoch 58/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.2787\n",
            "\n",
            "Epoch 00058: loss improved from 1.28976 to 1.27865, saving model to weights-improvement-2-58-1.2787.hdf5\n",
            "Epoch 59/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.2804\n",
            "\n",
            "Epoch 00059: loss did not improve from 1.27865\n",
            "Epoch 60/100\n",
            "129829/129829 [==============================] - 281s 2ms/step - loss: 1.2762\n",
            "\n",
            "Epoch 00060: loss improved from 1.27865 to 1.27621, saving model to weights-improvement-2-60-1.2762.hdf5\n",
            "Epoch 61/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.2691\n",
            "\n",
            "Epoch 00061: loss improved from 1.27621 to 1.26910, saving model to weights-improvement-2-61-1.2691.hdf5\n",
            "Epoch 62/100\n",
            "129829/129829 [==============================] - 283s 2ms/step - loss: 1.2639\n",
            "\n",
            "Epoch 00062: loss improved from 1.26910 to 1.26392, saving model to weights-improvement-2-62-1.2639.hdf5\n",
            "Epoch 63/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2653\n",
            "\n",
            "Epoch 00063: loss did not improve from 1.26392\n",
            "Epoch 64/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.2610\n",
            "\n",
            "Epoch 00064: loss improved from 1.26392 to 1.26098, saving model to weights-improvement-2-64-1.2610.hdf5\n",
            "Epoch 65/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2592\n",
            "\n",
            "Epoch 00065: loss improved from 1.26098 to 1.25920, saving model to weights-improvement-2-65-1.2592.hdf5\n",
            "Epoch 66/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2548\n",
            "\n",
            "Epoch 00066: loss improved from 1.25920 to 1.25484, saving model to weights-improvement-2-66-1.2548.hdf5\n",
            "Epoch 67/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.2522\n",
            "\n",
            "Epoch 00067: loss improved from 1.25484 to 1.25218, saving model to weights-improvement-2-67-1.2522.hdf5\n",
            "Epoch 68/100\n",
            "129829/129829 [==============================] - 280s 2ms/step - loss: 1.2494\n",
            "\n",
            "Epoch 00068: loss improved from 1.25218 to 1.24940, saving model to weights-improvement-2-68-1.2494.hdf5\n",
            "Epoch 69/100\n",
            "129829/129829 [==============================] - 284s 2ms/step - loss: 1.2463\n",
            "\n",
            "Epoch 00069: loss improved from 1.24940 to 1.24631, saving model to weights-improvement-2-69-1.2463.hdf5\n",
            "Epoch 70/100\n",
            "129829/129829 [==============================] - 285s 2ms/step - loss: 1.2416\n",
            "\n",
            "Epoch 00070: loss improved from 1.24631 to 1.24161, saving model to weights-improvement-2-70-1.2416.hdf5\n",
            "Epoch 71/100\n",
            "129829/129829 [==============================] - 285s 2ms/step - loss: 1.2382\n",
            "\n",
            "Epoch 00071: loss improved from 1.24161 to 1.23822, saving model to weights-improvement-2-71-1.2382.hdf5\n",
            "Epoch 72/100\n",
            "129829/129829 [==============================] - 282s 2ms/step - loss: 1.2388\n",
            "\n",
            "Epoch 00072: loss did not improve from 1.23822\n",
            "Epoch 73/100\n",
            "129829/129829 [==============================] - 274s 2ms/step - loss: 1.2363\n",
            "\n",
            "Epoch 00073: loss improved from 1.23822 to 1.23626, saving model to weights-improvement-2-73-1.2363.hdf5\n",
            "Epoch 74/100\n",
            "129829/129829 [==============================] - 267s 2ms/step - loss: 1.2279\n",
            "\n",
            "Epoch 00074: loss improved from 1.23626 to 1.22789, saving model to weights-improvement-2-74-1.2279.hdf5\n",
            "Epoch 75/100\n",
            "129829/129829 [==============================] - 262s 2ms/step - loss: 1.2231\n",
            "\n",
            "Epoch 00075: loss improved from 1.22789 to 1.22311, saving model to weights-improvement-2-75-1.2231.hdf5\n",
            "Epoch 76/100\n",
            "129829/129829 [==============================] - 261s 2ms/step - loss: 1.2261\n",
            "\n",
            "Epoch 00076: loss did not improve from 1.22311\n",
            "Epoch 77/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.2228\n",
            "\n",
            "Epoch 00077: loss improved from 1.22311 to 1.22275, saving model to weights-improvement-2-77-1.2228.hdf5\n",
            "Epoch 78/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.2201\n",
            "\n",
            "Epoch 00078: loss improved from 1.22275 to 1.22014, saving model to weights-improvement-2-78-1.2201.hdf5\n",
            "Epoch 79/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.2154\n",
            "\n",
            "Epoch 00079: loss improved from 1.22014 to 1.21539, saving model to weights-improvement-2-79-1.2154.hdf5\n",
            "Epoch 80/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.2146\n",
            "\n",
            "Epoch 00080: loss improved from 1.21539 to 1.21458, saving model to weights-improvement-2-80-1.2146.hdf5\n",
            "Epoch 81/100\n",
            "129829/129829 [==============================] - 264s 2ms/step - loss: 1.2109\n",
            "\n",
            "Epoch 00081: loss improved from 1.21458 to 1.21086, saving model to weights-improvement-2-81-1.2109.hdf5\n",
            "Epoch 82/100\n",
            "129829/129829 [==============================] - 263s 2ms/step - loss: 1.2082\n",
            "\n",
            "Epoch 00082: loss improved from 1.21086 to 1.20825, saving model to weights-improvement-2-82-1.2082.hdf5\n",
            "Epoch 83/100\n",
            "129829/129829 [==============================] - 269s 2ms/step - loss: 1.2113\n",
            "\n",
            "Epoch 00083: loss did not improve from 1.20825\n",
            "Epoch 84/100\n",
            "129829/129829 [==============================] - 261s 2ms/step - loss: 1.2031\n",
            "\n",
            "Epoch 00084: loss improved from 1.20825 to 1.20313, saving model to weights-improvement-2-84-1.2031.hdf5\n",
            "Epoch 85/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.2023\n",
            "\n",
            "Epoch 00085: loss improved from 1.20313 to 1.20228, saving model to weights-improvement-2-85-1.2023.hdf5\n",
            "Epoch 86/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.1998\n",
            "\n",
            "Epoch 00086: loss improved from 1.20228 to 1.19979, saving model to weights-improvement-2-86-1.1998.hdf5\n",
            "Epoch 87/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.1970\n",
            "\n",
            "Epoch 00087: loss improved from 1.19979 to 1.19701, saving model to weights-improvement-2-87-1.1970.hdf5\n",
            "Epoch 88/100\n",
            "129829/129829 [==============================] - 261s 2ms/step - loss: 1.1912\n",
            "\n",
            "Epoch 00088: loss improved from 1.19701 to 1.19124, saving model to weights-improvement-2-88-1.1912.hdf5\n",
            "Epoch 89/100\n",
            "129829/129829 [==============================] - 260s 2ms/step - loss: 1.1926\n",
            "\n",
            "Epoch 00089: loss did not improve from 1.19124\n",
            "Epoch 90/100\n",
            "129829/129829 [==============================] - 259s 2ms/step - loss: 1.1921\n",
            "\n",
            "Epoch 00090: loss did not improve from 1.19124\n",
            "Epoch 91/100\n",
            "129829/129829 [==============================] - 259s 2ms/step - loss: 1.1838\n",
            "\n",
            "Epoch 00091: loss improved from 1.19124 to 1.18377, saving model to weights-improvement-2-91-1.1838.hdf5\n",
            "Epoch 92/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1866\n",
            "\n",
            "Epoch 00092: loss did not improve from 1.18377\n",
            "Epoch 93/100\n",
            "129829/129829 [==============================] - 259s 2ms/step - loss: 1.1804\n",
            "\n",
            "Epoch 00093: loss improved from 1.18377 to 1.18039, saving model to weights-improvement-2-93-1.1804.hdf5\n",
            "Epoch 94/100\n",
            "129829/129829 [==============================] - 259s 2ms/step - loss: 1.1810\n",
            "\n",
            "Epoch 00094: loss did not improve from 1.18039\n",
            "Epoch 95/100\n",
            "129829/129829 [==============================] - 259s 2ms/step - loss: 1.1790\n",
            "\n",
            "Epoch 00095: loss improved from 1.18039 to 1.17904, saving model to weights-improvement-2-95-1.1790.hdf5\n",
            "Epoch 96/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1731\n",
            "\n",
            "Epoch 00096: loss improved from 1.17904 to 1.17308, saving model to weights-improvement-2-96-1.1731.hdf5\n",
            "Epoch 97/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1728\n",
            "\n",
            "Epoch 00097: loss improved from 1.17308 to 1.17281, saving model to weights-improvement-2-97-1.1728.hdf5\n",
            "Epoch 98/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1731\n",
            "\n",
            "Epoch 00098: loss did not improve from 1.17281\n",
            "Epoch 99/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1728\n",
            "\n",
            "Epoch 00099: loss improved from 1.17281 to 1.17277, saving model to weights-improvement-2-99-1.1728.hdf5\n",
            "Epoch 100/100\n",
            "129829/129829 [==============================] - 258s 2ms/step - loss: 1.1717\n",
            "\n",
            "Epoch 00100: loss improved from 1.17277 to 1.17172, saving model to weights-improvement-2-100-1.1717.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6b048be48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC9LnpOLO0qh",
        "colab_type": "text"
      },
      "source": [
        "#### So finally after running 100 epochs it is observed that the lowest loss is 1.17 which occurs at the last epoch `100`. And so we will use this trained model to make predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2VMzplGup9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('weights-improvement-2-100-1.1717.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE85gnlsPLgR",
        "colab_type": "text"
      },
      "source": [
        "#### Lets try out predictions by feeding a random seed sequence into the trained model.\n",
        "We can pick a random input pattern as our seed sequence, then print generated characters as we generate them.\n",
        "#### Generating 500 characters\n",
        "\n",
        "Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkhykz2Ri5lY",
        "colab_type": "code",
        "outputId": "7dc412c9-9c8e-44b3-c881-c00f10aa3f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "print(\"Index of the pattern to start with:\",start)\n",
        "pattern = dataX_padded[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of the pattern to start with: 118532\n",
            "Seed:\n",
            "\" nearly out of sight he said in a deep voice what are tarPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zlCfATa1P8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = list(dataX_padded[start])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DNLlBoy0lfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate characters\n",
        "import sys\n",
        "output = ''\n",
        "for i in range(500):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(n_vocab)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = int_to_char[index]\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  output = output+result\n",
        "  #sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  #print(len(pattern))\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni-cn5C4QMY6",
        "colab_type": "text"
      },
      "source": [
        "#### 500 characters generated `output`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoVM5spiII9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "99c4e701-7674-444a-c5aa-bf0e9154f3eb"
      },
      "source": [
        "output"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ce anlce tuittie toee iisself uhe had nevehl tuedked oure and tat as suoanary and tepiine tuesttoeling ano tound toeaked hirsoish cate ier stom temarked tarty suitting tuesbling anice and suusidlers whe suocess oed lerstrally hot teneing tatty suisui tusting about ier lnee ano taid alice and tead ier face ootoce oot tatted her hererally jt suitted toopling about ier lnee ano taid alice and teasg tight ie sane begors iere anice hasning ano tound teeahran anlce temarked tuitting toeaked hirsoays a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQsgr3JEQCDa",
        "colab_type": "text"
      },
      "source": [
        "#### Displaying the output in a readable manner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYOlM8YQML10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "61231e28-c8fb-41ca-a6b6-9f41613042f6"
      },
      "source": [
        "display = ''\n",
        "for i in range(len(output)):\n",
        "  display=display+output[i]\n",
        "  if i!=0 and i%100==0:\n",
        "    print(display)\n",
        "    display = ''\n",
        "  "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ce anlce tuittie toee iisself uhe had nevehl tuedked oure and tat as suoanary and tepiine tuesttoelin\n",
            "g ano tound toeaked hirsoish cate ier stom temarked tarty suitting tuesbling anice and suusidlers wh\n",
            "e suocess oed lerstrally hot teneing tatty suisui tusting about ier lnee ano taid alice and tead ier\n",
            " face ootoce oot tatted her hererally jt suitted toopling about ier lnee ano taid alice and teasg ti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIaqR6SvISLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "885fa36f-443c-4122-fce6-ca9b13ebf6f2"
      },
      "source": [
        "len(output)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8MF4fwIPmJ-",
        "colab_type": "text"
      },
      "source": [
        "Example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT__X7VzQMqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ae866a60-34ee-4daa-86d7-056f6b4386e4"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "print(\"Index of the pattern to start with:\",start)\n",
        "pattern = dataX_padded[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of the pattern to start with: 81210\n",
            "Seed:\n",
            "\" the soldiers were silent and lookePADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i4hH9X8QYP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = list(dataX_padded[start])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqotYpLQZbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate characters\n",
        "import sys\n",
        "output = ''\n",
        "for i in range(500):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(n_vocab)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = int_to_char[index]\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  output = output+result\n",
        "  #sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  #print(len(pattern))\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg-AvvL8QQYM",
        "colab_type": "text"
      },
      "source": [
        "#### 500 characters generated `output`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVZUIf89QdeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ad177eaa-9650-401b-c418-ccd9e0181088"
      },
      "source": [
        "output"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'d at suoanly temember and tead iimg alice anlver troeasimledt and as suosuratt tuesnlyo iad anyiousled oot tattedk gor yery wnder teady tosme at suopues anice hainine toease because tuiml tuedking tuesing anices anice hainine teplled iad anl at suopues toated anlce tuied tound temember about ier anice and io bno anlce temarked toeepy butsuted oot tatted oy horves anice whought alice and iere tairy foough hot seteated at suoanly temember teady tosme anice and io bno tound teeahr at suictutean tep'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcIS_8q3QYIs",
        "colab_type": "text"
      },
      "source": [
        "#### Displaying the output in a readable manner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipc5WQGNTxC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e7f5070f-5f19-4b2f-aa46-2c5bde713427"
      },
      "source": [
        "display = ''\n",
        "for i in range(len(output)):\n",
        "  display=display+output[i]\n",
        "  if i!=0 and i%100==0:\n",
        "    print(display)\n",
        "    display = ''\n",
        "  "
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d at suoanly temember and tead iimg alice anlver troeasimledt and as suosuratt tuesnlyo iad anyiousle\n",
            "d oot tattedk gor yery wnder teady tosme at suopues anice hainine toease because tuiml tuedking tues\n",
            "ing anices anice hainine teplled iad anl at suopues toated anlce tuied tound temember about ier anic\n",
            "e and io bno anlce temarked toeepy butsuted oot tatted oy horves anice whought alice and iere tairy \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yihB2MZFQbT0",
        "colab_type": "text"
      },
      "source": [
        "#### For reference all the weight files generated during improvement. Since the model at the last epoch performs with lowest loss we can download those weights and utilize them in future purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmV_uE2UBqco",
        "colab_type": "code",
        "outputId": "37e56c0c-5fdc-4352-9716-2c84a596554f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t\t\t       weights-improvement-2-45-1.3396.hdf5\n",
            "sample_data\t\t\t       weights-improvement-2-46-1.3383.hdf5\n",
            "weights-improvement-2-01-2.7441.hdf5   weights-improvement-2-47-1.3304.hdf5\n",
            "weights-improvement-2-02-2.4857.hdf5   weights-improvement-2-48-1.3303.hdf5\n",
            "weights-improvement-2-03-2.2977.hdf5   weights-improvement-2-49-1.3222.hdf5\n",
            "weights-improvement-2-04-2.1607.hdf5   weights-improvement-2-50-1.3165.hdf5\n",
            "weights-improvement-2-05-2.0581.hdf5   weights-improvement-2-51-1.3137.hdf5\n",
            "weights-improvement-2-06-1.9746.hdf5   weights-improvement-2-52-1.3100.hdf5\n",
            "weights-improvement-2-07-1.9173.hdf5   weights-improvement-2-53-1.3065.hdf5\n",
            "weights-improvement-2-08-1.8667.hdf5   weights-improvement-2-54-1.2988.hdf5\n",
            "weights-improvement-2-09-1.8223.hdf5   weights-improvement-2-55-1.2955.hdf5\n",
            "weights-improvement-2-100-1.1717.hdf5  weights-improvement-2-56-1.2898.hdf5\n",
            "weights-improvement-2-10-1.7864.hdf5   weights-improvement-2-58-1.2787.hdf5\n",
            "weights-improvement-2-11-1.7539.hdf5   weights-improvement-2-60-1.2762.hdf5\n",
            "weights-improvement-2-12-1.7235.hdf5   weights-improvement-2-61-1.2691.hdf5\n",
            "weights-improvement-2-13-1.7003.hdf5   weights-improvement-2-62-1.2639.hdf5\n",
            "weights-improvement-2-14-1.6713.hdf5   weights-improvement-2-64-1.2610.hdf5\n",
            "weights-improvement-2-15-1.6491.hdf5   weights-improvement-2-65-1.2592.hdf5\n",
            "weights-improvement-2-16-1.6299.hdf5   weights-improvement-2-66-1.2548.hdf5\n",
            "weights-improvement-2-17-1.6114.hdf5   weights-improvement-2-67-1.2522.hdf5\n",
            "weights-improvement-2-18-1.5898.hdf5   weights-improvement-2-68-1.2494.hdf5\n",
            "weights-improvement-2-19-1.5778.hdf5   weights-improvement-2-69-1.2463.hdf5\n",
            "weights-improvement-2-20-1.5616.hdf5   weights-improvement-2-70-1.2416.hdf5\n",
            "weights-improvement-2-21-1.5458.hdf5   weights-improvement-2-71-1.2382.hdf5\n",
            "weights-improvement-2-22-1.5336.hdf5   weights-improvement-2-73-1.2363.hdf5\n",
            "weights-improvement-2-23-1.5226.hdf5   weights-improvement-2-74-1.2279.hdf5\n",
            "weights-improvement-2-24-1.5097.hdf5   weights-improvement-2-75-1.2231.hdf5\n",
            "weights-improvement-2-25-1.4967.hdf5   weights-improvement-2-77-1.2228.hdf5\n",
            "weights-improvement-2-26-1.4884.hdf5   weights-improvement-2-78-1.2201.hdf5\n",
            "weights-improvement-2-27-1.4761.hdf5   weights-improvement-2-79-1.2154.hdf5\n",
            "weights-improvement-2-28-1.4678.hdf5   weights-improvement-2-80-1.2146.hdf5\n",
            "weights-improvement-2-29-1.4548.hdf5   weights-improvement-2-81-1.2109.hdf5\n",
            "weights-improvement-2-30-1.4466.hdf5   weights-improvement-2-82-1.2082.hdf5\n",
            "weights-improvement-2-31-1.4361.hdf5   weights-improvement-2-84-1.2031.hdf5\n",
            "weights-improvement-2-32-1.4287.hdf5   weights-improvement-2-85-1.2023.hdf5\n",
            "weights-improvement-2-33-1.4180.hdf5   weights-improvement-2-86-1.1998.hdf5\n",
            "weights-improvement-2-34-1.4111.hdf5   weights-improvement-2-87-1.1970.hdf5\n",
            "weights-improvement-2-35-1.4069.hdf5   weights-improvement-2-88-1.1912.hdf5\n",
            "weights-improvement-2-36-1.3977.hdf5   weights-improvement-2-91-1.1838.hdf5\n",
            "weights-improvement-2-37-1.3903.hdf5   weights-improvement-2-93-1.1804.hdf5\n",
            "weights-improvement-2-38-1.3829.hdf5   weights-improvement-2-95-1.1790.hdf5\n",
            "weights-improvement-2-39-1.3760.hdf5   weights-improvement-2-96-1.1731.hdf5\n",
            "weights-improvement-2-40-1.3694.hdf5   weights-improvement-2-97-1.1728.hdf5\n",
            "weights-improvement-2-41-1.3653.hdf5   weights-improvement-2-99-1.1728.hdf5\n",
            "weights-improvement-2-42-1.3558.hdf5   wonderland.txt\n",
            "weights-improvement-2-44-1.3463.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}